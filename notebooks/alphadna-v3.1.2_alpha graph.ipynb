{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, h5py\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='1'\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import logomaker\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import LightningModule\n",
    "from tqdm import tqdm\n",
    "import copy, math\n",
    "import collections\n",
    "\n",
    "from cremerl import utils, model_zoo, shuffle\n",
    "\n",
    "import shuffle_test\n",
    "\n",
    "#import gymnasium as gym\n",
    "\n",
    "import logging\n",
    "\n",
    "# Set the logging level to WARNING\n",
    "logging.getLogger(\"pytorch_lightning\").setLevel(logging.WARNING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "expt_name = 'DeepSTARR'\n",
    "\n",
    "# load data\n",
    "data_path = '../../data/'\n",
    "filepath = os.path.join(data_path, expt_name+'_data.h5')\n",
    "data_module = utils.H5DataModule(filepath, batch_size=100, lower_case=False, transpose=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yiyu/.conda/envs/tf_2/lib/python3.10/site-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      "2023-08-14 16:50:58.362075: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-08-14 16:50:58.975905: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/home/yiyu/.conda/envs/tf_2/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:432: PossibleUserWarning: The dataloader, predict_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 32 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b17b89031b354f8e914e61398b998d76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "deepstarr2 = model_zoo.deepstarr(2)\n",
    "loss = torch.nn.MSELoss()\n",
    "optimizer_dict = utils.configure_optimizer(deepstarr2, lr=0.001, weight_decay=1e-6, decay_factor=0.1, patience=5, monitor='val_loss')\n",
    "standard_cnn = model_zoo.DeepSTARR(deepstarr2,\n",
    "                                  criterion=loss,\n",
    "                                  optimizer=optimizer_dict)\n",
    "\n",
    "# load checkpoint for model with best validation performance\n",
    "standard_cnn = utils.load_model_from_checkpoint(standard_cnn, 'DeepSTARR_standard.ckpt')\n",
    "\n",
    "# evaluate best model\n",
    "pred = utils.get_predictions(standard_cnn, data_module.x_test[np.newaxis,100], batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_swap_greedy(x, x_mut, tile_ranges):\n",
    "    ori = x.copy()\n",
    "    mut = x_mut.copy()\n",
    "    for tile_range in tile_ranges:\n",
    "        ori[:, tile_range[0]:tile_range[1]] = x_mut[:, tile_range[0]:tile_range[1]]\n",
    "        mut[:, tile_range[0]:tile_range[1]] = x[:, tile_range[0]:tile_range[1]]\n",
    "\n",
    "    return ori, mut\n",
    "\n",
    "def get_score(pred):\n",
    "    score1 = pred[0] - pred[2]\n",
    "    score2 = pred[3] - pred[1]\n",
    "    return (score1+score2)[0], score1+score2\n",
    "\n",
    "def generate_tile_ranges(sequence_length, window_size, stride):\n",
    "    ranges = []\n",
    "    start = np.arange(0, sequence_length - window_size + stride, stride)\n",
    "\n",
    "    for s in start:\n",
    "        e = min(s + window_size, sequence_length)\n",
    "        ranges.append([s, e])\n",
    "\n",
    "    if start[-1] + window_size - stride < sequence_length:  # Adjust the last range\n",
    "        ranges[-1][1] = sequence_length\n",
    "\n",
    "    return ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(x, tile_range, tile_ranges_ori, trials):\n",
    "    test_batch = []\n",
    "    for i in range(trials):\n",
    "        test_batch.append(x)\n",
    "        x_mut = shuffle.dinuc_shuffle(x.copy())\n",
    "        test_batch.append(x_mut)\n",
    "\n",
    "        ori = x.copy()\n",
    "        mut = x_mut.copy()\n",
    "        \n",
    "        ori, mut = get_swap_greedy(ori, mut, tile_ranges_ori)\n",
    "        \n",
    "        ori[:, tile_range[0]:tile_range[1]] = x_mut[:, tile_range[0]:tile_range[1]]\n",
    "        mut[:, tile_range[0]:tile_range[1]] = x[:, tile_range[0]:tile_range[1]]\n",
    "        \n",
    "        test_batch.append(ori)\n",
    "        test_batch.append(mut)\n",
    "\n",
    "    #print(np.array(test_batch).shape)\n",
    "    return np.array(test_batch)\n",
    "\n",
    "\n",
    "def get_batch_score(pred, trials):\n",
    "\n",
    "    score = []\n",
    "    score_sep = []\n",
    "    for i in range(0, pred.shape[0], 2):\n",
    "        # print(f\"Viewing number {i}\")\n",
    "        score1 = pred[0] - pred[i]\n",
    "        score2 = pred[i+1] - pred[1]\n",
    "        score.append((np.sum((score1, score2)[0])).tolist()) #np.sum(score1+score2, keepdims=True)\n",
    "        score_sep.append((score1+score2).tolist())\n",
    "        \n",
    "    # print(score)\n",
    "        \n",
    "    final = np.sum(np.array(score), axis=0)/trials\n",
    "\n",
    "    #max_ind = np.argmax(final)\n",
    "    #block_ind = np.argmax(np.array(score)[:, max_ind])\n",
    "    #print(np.array(total_score)[:, max_ind])\n",
    "    total_score_sep = np.sum(np.array(score_sep), axis=0)/trials\n",
    "\n",
    "    #print(np.max(score))\n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extend_sequence(one_hot_sequence):\n",
    "    A, L = one_hot_sequence.shape\n",
    "\n",
    "    # Create an all-ones row\n",
    "    ones_row = np.zeros(L)\n",
    "\n",
    "    # Add the all-ones row to the original sequence\n",
    "    new_sequence = np.vstack((one_hot_sequence, ones_row))\n",
    "\n",
    "    return np.array(new_sequence, dtype='float32')\n",
    "\n",
    "def taking_action(sequence_with_ones, tile_range):\n",
    "    start_idx, end_idx = tile_range\n",
    "\n",
    "    # Ensure the start_idx and end_idx are within valid bounds\n",
    "    #if start_idx < 0 or start_idx >= sequence_with_ones.shape[1] or end_idx < 0 or end_idx >= sequence_with_ones.shape[1]:\n",
    "    #    raise ValueError(\"Invalid tile range indices.\")\n",
    "\n",
    "    # Copy the input sequence to avoid modifying the original sequence\n",
    "    modified_sequence = sequence_with_ones.copy()\n",
    "\n",
    "    # Modify the last row within the specified tile range\n",
    "    modified_sequence[-1, start_idx:end_idx] = 1\n",
    "\n",
    "    return np.array(modified_sequence, dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_elements(input_list):\n",
    "    input_list = input_list.tolist()\n",
    "    num_columns = 5  # Number of elements to process in each group\n",
    "\n",
    "    # Calculate the number of elements needed to pad the list\n",
    "    padding_length = num_columns - (len(input_list) % num_columns)\n",
    "    last_value = input_list[-1]\n",
    "    padded_list = input_list + [last_value] * padding_length\n",
    "\n",
    "    # Convert the padded list to a NumPy array for efficient operations\n",
    "    input_array = np.array(padded_list)\n",
    "    reshaped_array = input_array.reshape(-1, num_columns)\n",
    "\n",
    "    # Check if each row has the same value (all 0s or all 1s)\n",
    "    row_all_zeros = np.all(reshaped_array == 0, axis=1)\n",
    "    row_all_ones = np.all(reshaped_array == 1, axis=1)\n",
    "\n",
    "    # Replace all 0s with 0 and all 1s with 1 in the result array\n",
    "    output_array = np.where(row_all_zeros, 0, np.where(row_all_ones, 1, reshaped_array[:, 0]))\n",
    "\n",
    "    # Flatten the result array to get the final output list\n",
    "    output_list = output_array.flatten()\n",
    "\n",
    "    return output_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SeqGame:\n",
    "    def __init__(self, sequence, model_func):\n",
    "        self.seq = sequence\n",
    "        self.ori_seq = sequence.copy()\n",
    "        self.tile_ranges = generate_tile_ranges(sequence.shape[1], 5, 5)\n",
    "        self.levels = 20\n",
    "        self.num_trials = 10\n",
    "        self.action_size = 50\n",
    "        \n",
    "        self.prev_score = -float(\"inf\")\n",
    "        self.current_score = 0\n",
    "        \n",
    "        self.trainer = pl.Trainer(accelerator='gpu', devices='1', logger=None, enable_progress_bar=False)\n",
    "        self.model = model_func\n",
    "        \n",
    "        if self.seq.shape[0]!=5:\n",
    "            self.seq = extend_sequence(self.seq)\n",
    "            self.ori_seq = extend_sequence(self.ori_seq)\n",
    "        \n",
    "    \n",
    "    def get_initial_state(self):\n",
    "        self.seq = self.ori_seq.copy()\n",
    "        \n",
    "        return self.seq\n",
    "    \n",
    "    \n",
    "    def get_next_state(self, action, tile_ranges_done):\n",
    "        self.prev_score = self.current_score\n",
    "        # self.current_level += 1\n",
    "        \n",
    "        self.seq = taking_action(self.seq, self.tile_ranges[action])\n",
    "        \n",
    "        batch = get_batch(self.seq[:4, :], self.tile_ranges[action], tile_ranges_done, self.num_trials)\n",
    "        dataloader = torch.utils.data.DataLoader(batch, batch_size=100, shuffle=False)\n",
    "        pred = np.concatenate(self.trainer.predict(self.model, dataloaders=dataloader))\n",
    "        \n",
    "        self.current_score = np.tanh(1 * get_batch_score(pred, self.num_trials)) #ADDED TANH\n",
    "        \n",
    "        return self.seq\n",
    "    \n",
    "    def get_valid_moves(self):\n",
    "        return (convert_elements(self.seq[-1, :]) == 0).astype(np.uint8)\n",
    "    \n",
    "    def terminate(self, level, current_score, parent_score): #state\n",
    "        # if self.current_level >= self.levels:\n",
    "        #     return True\n",
    "        # if self.current_score < self.prev_score:\n",
    "        #     return True\n",
    "        \n",
    "        if level >= self.levels:\n",
    "            return True\n",
    "        if current_score < parent_score:\n",
    "            return True\n",
    "    \n",
    "        return False\n",
    "    \n",
    "    def set_seq(self, seq):\n",
    "        self.seq = seq\n",
    "    \n",
    "    def get_seq(self):\n",
    "        return self.seq.copy()\n",
    "    \n",
    "    def get_score(self):\n",
    "        return self.current_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, action, state, done, reward, mcts, level, tile_ranges_done, parent=None):\n",
    "        self.env = parent.env\n",
    "        self.action = action\n",
    "        \n",
    "        self.is_expanded = False\n",
    "        self.parent = parent\n",
    "        self.children = {}\n",
    "        \n",
    "        self.action_space_size = self.env.action_size\n",
    "        self.child_total_value = np.zeros(\n",
    "            [self.action_space_size], dtype=np.float32\n",
    "        ) # Q\n",
    "        self.child_priors = np.zeros([self.action_space_size], dtype=np.float32) # P\n",
    "        self.child_number_visits = np.zeros(\n",
    "            [self.action_space_size], dtype=np.float32\n",
    "        ) # N\n",
    "        self.valid_actions = (convert_elements(state[-1, :]) == 0).astype(np.uint8)\n",
    "        \n",
    "        self.reward = reward\n",
    "        self.done = done\n",
    "        self.state = state\n",
    "        self.level = level\n",
    "        \n",
    "        self.tile_ranges_done = tile_ranges_done\n",
    "        \n",
    "        self.mcts = mcts\n",
    "    \n",
    "    @property\n",
    "    def number_visits(self):\n",
    "        return self.parent.child_number_visits[self.action]\n",
    "    \n",
    "    @number_visits.setter\n",
    "    def number_visits(self, value):\n",
    "        self.parent.child_number_visits[self.action] = value\n",
    "        \n",
    "    @property\n",
    "    def total_value(self):\n",
    "        return self.parent.child_total_value[self.action]\n",
    "    \n",
    "    @total_value.setter\n",
    "    def total_value(self, value):\n",
    "        self.parent.child_total_value[self.action] = value\n",
    "        \n",
    "    def child_Q(self):\n",
    "        return self.child_total_value / (1 + self.child_number_visits)\n",
    "    \n",
    "    def child_U(self):\n",
    "        return (\n",
    "            math.sqrt(self.number_visits)\n",
    "            * self.child_priors\n",
    "            / (1 + self.child_number_visits)\n",
    "        )\n",
    "    \n",
    "    def best_action(self):\n",
    "        child_score = self.child_Q() + self.mcts.c_puct * self.child_U()\n",
    "        masked_child_score = child_score\n",
    "        # masked_child_score[~self.valid_actions] = -np.inf\n",
    "        masked_child_score = masked_child_score * self.valid_actions\n",
    "        return np.argmax(masked_child_score)\n",
    "    \n",
    "    def select(self):\n",
    "        current_node = self\n",
    "        while current_node.is_expanded:\n",
    "            best_action = current_node.best_action()\n",
    "            current_node = current_node.get_child(best_action)\n",
    "        return current_node\n",
    "    \n",
    "    def expand(self, child_priors):\n",
    "        self.is_expanded = True\n",
    "        self.child_priors = child_priors\n",
    "        \n",
    "    def set_state(self, state):\n",
    "        self.state = state\n",
    "        self.valid_actions = (convert_elements(state[-1, :]) == 0).astype(np.uint8)\n",
    "    \n",
    "    def get_child(self, action):\n",
    "        if action not in self.children:\n",
    "\n",
    "            self.env.set_seq(self.state.copy())\n",
    "            next_state = self.env.get_next_state(action, self.tile_ranges_done)\n",
    "            # self.tile_ranges_done.append(self.tile_ranges.pop(action))\n",
    "            new_tile_ranges_done = copy.deepcopy(self.tile_ranges_done)\n",
    "            # print(new_tile_ranges_done)\n",
    "            new_tile_ranges_done.append(self.env.tile_ranges[action])\n",
    "            # swap tile_ranges\n",
    "            reward = self.env.get_score()\n",
    "            terminated = self.env.terminate(self.level, reward, self.parent.reward)\n",
    "            self.children[action] = Node(\n",
    "                state=next_state, \n",
    "                action=action, \n",
    "                parent=self, \n",
    "                reward=reward,\n",
    "                done=terminated,\n",
    "                mcts=self.mcts, \n",
    "                level=self.level+1, \n",
    "                tile_ranges_done=new_tile_ranges_done\n",
    "            )\n",
    "        return self.children[action]\n",
    "    \n",
    "    def backup(self, value):\n",
    "        current = self\n",
    "        while current.parent is not None:\n",
    "            current.number_visits += 1\n",
    "            current.total_value += value\n",
    "            current = current.parent\n",
    "\n",
    "class RootParentNode:\n",
    "    def __init__(self, env):\n",
    "        self.parent = None\n",
    "        self.child_total_value = collections.defaultdict(float)\n",
    "        self.child_number_visits = collections.defaultdict(float)\n",
    "        self.env = env\n",
    "        self.reward = -np.inf\n",
    "\n",
    "class MCTS:\n",
    "    def __init__(self, model, mcts_param):\n",
    "        self.model = model\n",
    "        self.temperature = mcts_param[\"temperature\"]\n",
    "        self.dir_epsilon = mcts_param[\"dirichlet_epsilon\"]\n",
    "        self.dir_noise = mcts_param[\"dirichlet_noise\"]\n",
    "        self.num_sims = mcts_param[\"num_simulations\"]\n",
    "        self.exploit = mcts_param[\"argmax_tree_policy\"]\n",
    "        self.add_dirichlet_noise = mcts_param[\"add_dirichlet_noise\"]\n",
    "        self.c_puct = mcts_param[\"puct_coefficient\"]\n",
    "    \n",
    "    def compute_action(self, node):\n",
    "        for _ in range(self.num_sims):\n",
    "            leaf = node.select()\n",
    "            if leaf.done:\n",
    "                value = leaf.reward\n",
    "            else:\n",
    "                child_priors, value = self.model(torch.tensor(leaf.state).unsqueeze(0))\n",
    "                child_priors = torch.softmax(child_priors, axis=1).squeeze(0).cpu().detach().numpy()\n",
    "                if self.add_dirichlet_noise:\n",
    "                    child_priors = (1 - self.dir_epsilon) * child_priors\n",
    "                    child_priors += self.dir_epsilon * np.random.dirichlet(\n",
    "                        [self.dir_noise] * child_priors.size\n",
    "                    )\n",
    "                \n",
    "                leaf.expand(child_priors)\n",
    "            leaf.backup(value)\n",
    "            \n",
    "        tree_policy = node.child_number_visits / node.number_visits\n",
    "        tree_policy = tree_policy / np.max(tree_policy)\n",
    "        tree_policy = np.power(tree_policy, self.temperature)\n",
    "        tree_policy = tree_policy / np.sum(tree_policy)\n",
    "        if self.exploit:\n",
    "            action = np.argmax(tree_policy)\n",
    "        else:\n",
    "            action = np.random.choice(np.arange(node.action_space_size), p=tree_policy)\n",
    "        return tree_policy, action, node.children[action]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_v0(nn.Module):\n",
    "    def __init__(self, action_dim):\n",
    "        super(CNN_v0, self).__init__()\n",
    "        \n",
    "        self.convblock1 = nn.Sequential(\n",
    "            nn.Conv1d(5, 32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm1d(32), \n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.convblock2 = nn.Sequential(\n",
    "            nn.Conv1d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm1d(64), \n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.convblock3 = nn.Sequential(\n",
    "            nn.Conv1d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm1d(128), \n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.policyHead = nn.Sequential(\n",
    "            nn.Conv1d(128, 50, kernel_size=3, padding=1), \n",
    "            nn.BatchNorm1d(50), \n",
    "            nn.Flatten(), \n",
    "            nn.Linear(50 * 249, action_dim) # 4 * action_dim\n",
    "        )\n",
    "        \n",
    "        self.valueHead = nn.Sequential(\n",
    "            nn.Conv1d(128, 50, kernel_size=3, padding=1), \n",
    "            nn.BatchNorm1d(50), \n",
    "            nn.Flatten(), \n",
    "            nn.Linear(50 * 249, 128), \n",
    "            nn.Linear(128, 1), \n",
    "            nn.Tanh()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.convblock1(x)\n",
    "        x = self.convblock2(x)\n",
    "        x = self.convblock3(x)\n",
    "        \n",
    "        policy = self.policyHead(x)\n",
    "        value = self.valueHead(x)\n",
    "        return policy, value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence = data_module.x_test[1].numpy()\n",
    "seqgame = SeqGame(sequence, standard_cnn)\n",
    "\n",
    "\n",
    "mcts_config = {\n",
    "    \"puct_coefficient\": 2.0,\n",
    "    \"num_simulations\": 10000,\n",
    "    \"temperature\": 1.5,\n",
    "    \"dirichlet_epsilon\": 0.25,\n",
    "    \"dirichlet_noise\": 0.03,\n",
    "    \"argmax_tree_policy\": False,\n",
    "    \"add_dirichlet_noise\": True,\n",
    "}\n",
    "\n",
    "model = CNN_v0(seqgame.action_size)\n",
    "model.eval()\n",
    "\n",
    "mcts = MCTS(model, mcts_config)\n",
    "\n",
    "# Get the initial sequence and create the root node\n",
    "initial_sequence = seqgame.get_seq()\n",
    "    \n",
    "root_node = Node(\n",
    "    state=initial_sequence,\n",
    "    reward=0,\n",
    "    done=False,\n",
    "    action=None,\n",
    "    parent=RootParentNode(env=seqgame),\n",
    "    mcts=mcts, \n",
    "    level=0, \n",
    "    tile_ranges_done=[]\n",
    ")\n",
    "\n",
    "while not root_node.done:  # Loop until the root node indicates the game is done\n",
    "    print(\"Current sequence:\", convert_elements(root_node.state[-1,:]))\n",
    "    valid_moves = root_node.valid_actions\n",
    "    print(\"Valid moves:\", [i for i in range(seqgame.action_size) if valid_moves[i] == 1])\n",
    "\n",
    "    # Perform simulations and select an action using MCTS\n",
    "    mcts_probs, action, next_node = mcts.compute_action(root_node)\n",
    "    print(\"MCTS probabilities:\", mcts_probs)\n",
    "    print(\"Selected action:\", action)\n",
    "    \n",
    "\n",
    "    if valid_moves[action] == 0:\n",
    "        print(\"Invalid action, skipping.\")\n",
    "        continue\n",
    "    \n",
    "    print(root_node.tile_ranges_done)\n",
    "    print(root_node.reward)\n",
    "\n",
    "    root_node = next_node\n",
    "\n",
    "print(\"Game ended.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlphaDNA:\n",
    "    def __init__(self, model, optimizer, env, args, mcts_config = {\n",
    "        \"puct_coefficient\": 2.0,\n",
    "        \"num_simulations\": 10000,\n",
    "        \"temperature\": 1.5,\n",
    "        \"dirichlet_epsilon\": 0.25,\n",
    "        \"dirichlet_noise\": 0.03,\n",
    "        \"argmax_tree_policy\": False,\n",
    "        \"add_dirichlet_noise\": True,}\n",
    "                 ):\n",
    "        self.model = model\n",
    "        self.optimizer = optimizer\n",
    "        self.env = env\n",
    "        self.args = args\n",
    "        self.mcts = MCTS(model, mcts_config)\n",
    "        \n",
    "        self.initial_sequence = env.get_seq()\n",
    "    \n",
    "    def selfPlay(self):\n",
    "        memory = []\n",
    "\n",
    "        root_node = Node(\n",
    "            state=self.initial_sequence,\n",
    "            reward=0,\n",
    "            done=False,\n",
    "            action=None,\n",
    "            parent=RootParentNode(env=seqgame),\n",
    "            mcts=self.mcts, \n",
    "            level=0, \n",
    "            tile_ranges_done=[]\n",
    "        )\n",
    "\n",
    "        while True:  # Loop until the root node indicates the game is done\n",
    "            valid_moves = root_node.valid_actions\n",
    "            mcts_probs, action, next_node = self.mcts.compute_action(root_node)\n",
    "            \n",
    "            memory.append((root_node.state, mcts_probs, next_node.reward))\n",
    "\n",
    "            if valid_moves[action] == 0:\n",
    "                print(\"Invalid action, skipping.\")\n",
    "                continue\n",
    "            \n",
    "            if next_node.done:\n",
    "                return memory\n",
    "\n",
    "            root_node = next_node\n",
    "    \n",
    "    def train(self, memory):\n",
    "        np.random.shuffle(memory)\n",
    "        for batchIdx in range(0, len(memory), self.args['batch_size']):\n",
    "            sample = memory[batchIdx:min(len(memory) - 1, batchIdx + self.args['batch_size'])]\n",
    "            state, policy_targets, value_targets = zip(*sample)\n",
    "            \n",
    "            state, policy_targets, value_targets = np.array(state), np.array(policy_targets), np.array(value_targets)\n",
    "            \n",
    "            state = torch.tensor(state, dtype=torch.float32)\n",
    "            policy_targets = torch.tensor(policy_targets, dtype=torch.float32)\n",
    "            value_targets = torch.tensor(value_targets, dtype=torch.float32)\n",
    "            \n",
    "            out_policy, out_value = self.model(state)\n",
    "            \n",
    "            priors = nn.Softmax(dim=-1)(out_policy)\n",
    "            \n",
    "            policy_loss = torch.mean(\n",
    "                -torch.sum(policy_targets * torch.log(priors), dim=-1)\n",
    "            )\n",
    "            value_loss = torch.mean(torch.pow(value_targets - out_value, 2))\n",
    "            \n",
    "            total_loss = policy_loss + value_loss\n",
    "            \n",
    "            self.optimizer.zero_grad()\n",
    "            total_loss.backward()\n",
    "            self.optimizer.step()\n",
    "            \n",
    "            return total_loss\n",
    "        \n",
    "    def learn(self):\n",
    "        lowest_loss = np.inf\n",
    "        for iteration in tqdm(range(self.args['num_iterations'])):\n",
    "            print(f\"Iteration {iteration}:\")\n",
    "            memory = []\n",
    "            \n",
    "            self.model.eval()\n",
    "            for selfPlay_iteration in tqdm(range(self.args['num_selfPlay_iterations'])):\n",
    "                print(f\"SelfPlay Iteration {selfPlay_iteration}\")\n",
    "                memory += self.selfPlay()\n",
    "            \n",
    "            self.model.train()\n",
    "            for epoch in tqdm(range(self.args['num_epochs'])):\n",
    "                print(f\"Training Epoch {epoch}\")\n",
    "                loss = self.train(memory)\n",
    "                print(f\"Total Loss: {loss}\")\n",
    "                \n",
    "                if loss < lowest_loss:\n",
    "                    print(\"Saving the best model\")\n",
    "                    lowest_loss = loss\n",
    "                    torch.save(self.model.state_dict(), \"best_model.pt\")\n",
    "                    torch.save(self.optimizer.state_dict(), \"best_optimizer.pt\")\n",
    "                \n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SelfPlay Iteration 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SelfPlay Iteration 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:11<00:00,  5.60s/it]\n",
      "100%|██████████| 4/4 [00:00<00:00, 44.70it/s]\n",
      "  5%|▌         | 1/20 [00:11<03:34, 11.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 0\n",
      "Total Loss: 4.756659507751465\n",
      "Saving the best model\n",
      "Training Epoch 1\n",
      "Total Loss: 23.226892471313477\n",
      "Training Epoch 2\n",
      "Total Loss: 29.217710494995117\n",
      "Training Epoch 3\n",
      "Total Loss: 2.910061836242676\n",
      "Saving the best model\n",
      "Iteration 1:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SelfPlay Iteration 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SelfPlay Iteration 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:29<00:00, 14.81s/it]\n",
      "100%|██████████| 4/4 [00:00<00:00, 102.74it/s]\n",
      " 10%|█         | 2/20 [00:40<06:37, 22.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 0\n",
      "Total Loss: 30.931066513061523\n",
      "Training Epoch 1\n",
      "Total Loss: 11.025620460510254\n",
      "Training Epoch 2\n",
      "Total Loss: 23.65279769897461\n",
      "Training Epoch 3\n",
      "Total Loss: 15.953851699829102\n",
      "Iteration 2:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SelfPlay Iteration 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SelfPlay Iteration 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:50<00:00, 25.04s/it]\n",
      "100%|██████████| 4/4 [00:00<00:00, 103.96it/s]\n",
      " 15%|█▌        | 3/20 [01:31<09:53, 34.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 0\n",
      "Total Loss: 15.782939910888672\n",
      "Training Epoch 1\n",
      "Total Loss: 24.044506072998047\n",
      "Training Epoch 2\n",
      "Total Loss: 13.096134185791016\n",
      "Training Epoch 3\n",
      "Total Loss: 8.670369148254395\n",
      "Iteration 3:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SelfPlay Iteration 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SelfPlay Iteration 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:29<00:00, 14.85s/it]\n",
      "100%|██████████| 4/4 [00:00<00:00, 101.19it/s]\n",
      " 20%|██        | 4/20 [02:00<08:45, 32.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 0\n",
      "Total Loss: 10.551641464233398\n",
      "Training Epoch 1\n",
      "Total Loss: 7.007012844085693\n",
      "Training Epoch 2\n",
      "Total Loss: 4.480101585388184\n",
      "Training Epoch 3\n",
      "Total Loss: 13.354626655578613\n",
      "Iteration 4:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SelfPlay Iteration 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SelfPlay Iteration 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:20<00:00, 10.42s/it]\n",
      "100%|██████████| 4/4 [00:00<00:00, 120.10it/s]\n",
      " 25%|██▌       | 5/20 [02:21<07:08, 28.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 0\n",
      "Total Loss: 6.544302940368652\n",
      "Training Epoch 1\n",
      "Total Loss: 2.9155566692352295\n",
      "Training Epoch 2\n",
      "Total Loss: 8.83521556854248\n",
      "Training Epoch 3\n",
      "Total Loss: 3.5410900115966797\n",
      "Iteration 5:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SelfPlay Iteration 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SelfPlay Iteration 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:28<00:00, 14.02s/it]\n",
      "100%|██████████| 4/4 [00:00<00:00, 119.65it/s]\n",
      " 30%|███       | 6/20 [02:49<06:37, 28.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 0\n",
      "Total Loss: 5.355292320251465\n",
      "Training Epoch 1\n",
      "Total Loss: 7.026004314422607\n",
      "Training Epoch 2\n",
      "Total Loss: 6.285071849822998\n",
      "Training Epoch 3\n",
      "Total Loss: 5.9423909187316895\n",
      "Iteration 6:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SelfPlay Iteration 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SelfPlay Iteration 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:21<00:00, 10.97s/it]\n",
      "100%|██████████| 4/4 [00:00<00:00, 116.56it/s]\n",
      " 35%|███▌      | 7/20 [03:11<05:41, 26.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 0\n",
      "Total Loss: 7.398082733154297\n",
      "Training Epoch 1\n",
      "Total Loss: 8.668726921081543\n",
      "Training Epoch 2\n",
      "Total Loss: 5.050792217254639\n",
      "Training Epoch 3\n",
      "Total Loss: 3.540869951248169\n",
      "Iteration 7:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SelfPlay Iteration 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SelfPlay Iteration 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:34<00:00, 17.40s/it]\n",
      "100%|██████████| 4/4 [00:00<00:00, 42.79it/s]\n",
      " 40%|████      | 8/20 [03:46<05:48, 29.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 0\n",
      "Total Loss: 3.7958462238311768\n",
      "Training Epoch 1\n",
      "Total Loss: 1.939974069595337\n",
      "Saving the best model\n",
      "Training Epoch 2\n",
      "Total Loss: 4.334042549133301\n",
      "Training Epoch 3\n",
      "Total Loss: 5.36262321472168\n",
      "Iteration 8:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SelfPlay Iteration 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SelfPlay Iteration 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:35<00:00, 17.99s/it]\n",
      "100%|██████████| 4/4 [00:00<00:00, 101.42it/s]\n",
      " 45%|████▌     | 9/20 [04:22<05:43, 31.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 0\n",
      "Total Loss: 3.2128818035125732\n",
      "Training Epoch 1\n",
      "Total Loss: 3.0261423587799072\n",
      "Training Epoch 2\n",
      "Total Loss: 4.813085556030273\n",
      "Training Epoch 3\n",
      "Total Loss: 3.4427661895751953\n",
      "Iteration 9:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SelfPlay Iteration 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SelfPlay Iteration 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:18<00:00,  9.38s/it]\n",
      "100%|██████████| 4/4 [00:00<00:00, 48.49it/s]\n",
      " 50%|█████     | 10/20 [04:41<04:33, 27.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 0\n",
      "Total Loss: 7.917288303375244\n",
      "Training Epoch 1\n",
      "Total Loss: 6.972733974456787\n",
      "Training Epoch 2\n",
      "Total Loss: 2.9865565299987793\n",
      "Training Epoch 3\n",
      "Total Loss: 4.699330806732178\n",
      "Iteration 10:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SelfPlay Iteration 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SelfPlay Iteration 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:15<00:00,  7.55s/it]\n",
      "100%|██████████| 4/4 [00:00<00:00, 48.62it/s]\n",
      " 55%|█████▌    | 11/20 [04:56<03:32, 23.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 0\n",
      "Total Loss: 1.4707512855529785\n",
      "Saving the best model\n",
      "Training Epoch 1\n",
      "Total Loss: 1.0331815481185913\n",
      "Saving the best model\n",
      "Training Epoch 2\n",
      "Total Loss: 2.694047451019287\n",
      "Training Epoch 3\n",
      "Total Loss: 1.2465119361877441\n",
      "Iteration 11:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SelfPlay Iteration 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SelfPlay Iteration 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1/2 [00:09<00:09,  9.85s/it]\n",
      " 55%|█████▌    | 11/20 [05:06<04:10, 27.87s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 26\u001b[0m\n\u001b[1;32m     15\u001b[0m mcts_config \u001b[39m=\u001b[39m {\n\u001b[1;32m     16\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mpuct_coefficient\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m2.0\u001b[39m,\n\u001b[1;32m     17\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mnum_simulations\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m1000\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39madd_dirichlet_noise\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m     23\u001b[0m }\n\u001b[1;32m     25\u001b[0m alphadna \u001b[39m=\u001b[39m AlphaDNA(model, optimizer, seqgame, args, mcts_config)\n\u001b[0;32m---> 26\u001b[0m alphadna\u001b[39m.\u001b[39;49mlearn()\n",
      "Cell \u001b[0;32mIn[11], line 86\u001b[0m, in \u001b[0;36mAlphaDNA.learn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[39mfor\u001b[39;00m selfPlay_iteration \u001b[39min\u001b[39;00m tqdm(\u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs[\u001b[39m'\u001b[39m\u001b[39mnum_selfPlay_iterations\u001b[39m\u001b[39m'\u001b[39m])):\n\u001b[1;32m     85\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mSelfPlay Iteration \u001b[39m\u001b[39m{\u001b[39;00mselfPlay_iteration\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 86\u001b[0m     memory \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mselfPlay()\n\u001b[1;32m     88\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mtrain()\n\u001b[1;32m     89\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m tqdm(\u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs[\u001b[39m'\u001b[39m\u001b[39mnum_epochs\u001b[39m\u001b[39m'\u001b[39m])):\n",
      "Cell \u001b[0;32mIn[11], line 35\u001b[0m, in \u001b[0;36mAlphaDNA.selfPlay\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:  \u001b[39m# Loop until the root node indicates the game is done\u001b[39;00m\n\u001b[1;32m     34\u001b[0m     valid_moves \u001b[39m=\u001b[39m root_node\u001b[39m.\u001b[39mvalid_actions\n\u001b[0;32m---> 35\u001b[0m     mcts_probs, action, next_node \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmcts\u001b[39m.\u001b[39;49mcompute_action(root_node)\n\u001b[1;32m     37\u001b[0m     memory\u001b[39m.\u001b[39mappend((root_node\u001b[39m.\u001b[39mstate, mcts_probs, next_node\u001b[39m.\u001b[39mreward))\n\u001b[1;32m     39\u001b[0m     \u001b[39mif\u001b[39;00m valid_moves[action] \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n",
      "Cell \u001b[0;32mIn[9], line 133\u001b[0m, in \u001b[0;36mMCTS.compute_action\u001b[0;34m(self, node)\u001b[0m\n\u001b[1;32m    131\u001b[0m     value \u001b[39m=\u001b[39m leaf\u001b[39m.\u001b[39mreward\n\u001b[1;32m    132\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 133\u001b[0m     child_priors, value \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel(torch\u001b[39m.\u001b[39;49mtensor(leaf\u001b[39m.\u001b[39;49mstate)\u001b[39m.\u001b[39;49munsqueeze(\u001b[39m0\u001b[39;49m))\n\u001b[1;32m    134\u001b[0m     child_priors \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39msoftmax(child_priors, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39msqueeze(\u001b[39m0\u001b[39m)\u001b[39m.\u001b[39mcpu()\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mnumpy()\n\u001b[1;32m    135\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39madd_dirichlet_noise:\n",
      "File \u001b[0;32m~/.conda/envs/tf_2/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[10], line 40\u001b[0m, in \u001b[0;36mCNN_v0.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[0;32m---> 40\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconvblock1(x)\n\u001b[1;32m     41\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconvblock2(x)\n\u001b[1;32m     42\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconvblock3(x)\n",
      "File \u001b[0;32m~/.conda/envs/tf_2/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.conda/envs/tf_2/lib/python3.10/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    218\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m~/.conda/envs/tf_2/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.conda/envs/tf_2/lib/python3.10/site-packages/torch/nn/modules/conv.py:313\u001b[0m, in \u001b[0;36mConv1d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    312\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 313\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_conv_forward(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "File \u001b[0;32m~/.conda/envs/tf_2/lib/python3.10/site-packages/torch/nn/modules/conv.py:309\u001b[0m, in \u001b[0;36mConv1d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mzeros\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    306\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mconv1d(F\u001b[39m.\u001b[39mpad(\u001b[39minput\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode),\n\u001b[1;32m    307\u001b[0m                     weight, bias, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstride,\n\u001b[1;32m    308\u001b[0m                     _single(\u001b[39m0\u001b[39m), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdilation, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroups)\n\u001b[0;32m--> 309\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mconv1d(\u001b[39minput\u001b[39;49m, weight, bias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstride,\n\u001b[1;32m    310\u001b[0m                 \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgroups)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "sequence = data_module.x_test[1].numpy()\n",
    "seqgame = SeqGame(sequence, standard_cnn)\n",
    "\n",
    "model = CNN_v0(seqgame.action_size)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=0.0001)\n",
    "\n",
    "args = {\n",
    "    'num_iterations': 20, # 3 \n",
    "    'num_selfPlay_iterations': 2, # 500\n",
    "    'num_epochs': 4, \n",
    "    'batch_size': 2, # 64\n",
    "}\n",
    "\n",
    "mcts_config = {\n",
    "    \"puct_coefficient\": 2.0,\n",
    "    \"num_simulations\": 1000,\n",
    "    \"temperature\": 1.5,\n",
    "    \"dirichlet_epsilon\": 0.25,\n",
    "    \"dirichlet_noise\": 0.03,\n",
    "    \"argmax_tree_policy\": False,\n",
    "    \"add_dirichlet_noise\": True,\n",
    "}\n",
    "\n",
    "alphadna = AlphaDNA(model, optimizer, seqgame, args, mcts_config)\n",
    "alphadna.learn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current sequence: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0.]\n",
      "Valid moves: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]\n",
      "MCTS probabilities: [0.0000000e+00 0.0000000e+00 0.0000000e+00 2.8947314e-05 1.1986699e-05\n",
      " 5.5709138e-06 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 5.5709138e-06 6.8615860e-05 0.0000000e+00\n",
      " 3.0324213e-06 8.5769825e-06 5.5709138e-06 0.0000000e+00 5.5709138e-06\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 3.0324213e-06 9.9272728e-01\n",
      " 0.0000000e+00 1.1986699e-05 8.8792236e-05 3.9114122e-05 4.4567310e-05\n",
      " 6.5737288e-03 0.0000000e+00 0.0000000e+00 0.0000000e+00 6.2284715e-05\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 3.0324213e-06 0.0000000e+00\n",
      " 2.8146233e-04 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 5.5709138e-06 0.0000000e+00 1.5756925e-05 0.0000000e+00 0.0000000e+00]\n",
      "Selected action: 24\n",
      "[]\n",
      "0\n",
      "Current sequence: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0.]\n",
      "Valid moves: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]\n",
      "MCTS probabilities: [0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 4.1567764e-06\n",
      " 0.0000000e+00 0.0000000e+00 4.1567764e-06 0.0000000e+00 1.9318952e-06\n",
      " 2.8392942e-05 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 1.9318952e-06\n",
      " 0.0000000e+00 2.8623355e-04 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 8.3676634e-05 3.7179336e-07 0.0000000e+00 9.9958080e-01 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 8.4127232e-06 0.0000000e+00 0.0000000e+00]\n",
      "Selected action: 38\n",
      "[[120, 125]]\n",
      "0.15048762696797766\n",
      "Current sequence: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0.]\n",
      "Valid moves: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]\n",
      "MCTS probabilities: [1.6564836e-05 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 7.2970233e-06 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 5.6572020e-07\n",
      " 5.4003317e-06 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 2.9395685e-06 0.0000000e+00 6.8604211e-05\n",
      " 2.0001229e-07 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 9.9989843e-01 0.0000000e+00 0.0000000e+00]\n",
      "Selected action: 47\n",
      "[[120, 125], [190, 195]]\n",
      "0.3342162392557359\n",
      "Current sequence: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0.]\n",
      "Valid moves: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 39, 40, 41, 42, 43, 44, 45, 46, 48, 49]\n",
      "MCTS probabilities: [2.9497412e-06 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 3.6871765e-07 0.0000000e+00 2.9339422e-05 2.4143264e-06\n",
      " 0.0000000e+00 0.0000000e+00 5.4337370e-04 0.0000000e+00 0.0000000e+00\n",
      " 9.9939775e-01 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 4.7559579e-06 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 1.8289198e-05 0.0000000e+00 1.3036137e-07\n",
      " 3.6871765e-07 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 1.3036137e-07 0.0000000e+00 1.3036137e-07 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      "Selected action: 20\n",
      "[[120, 125], [190, 195], [235, 240]]\n",
      "0.23011158653668787\n",
      "Current sequence: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
      " 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0.]\n",
      "Valid moves: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 39, 40, 41, 42, 43, 44, 45, 46, 48, 49]\n",
      "MCTS probabilities: [1.1719125e-05 6.5714103e-06 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 5.1415896e-05 3.3146691e-05 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 9.9967456e-01 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 1.3778821e-06 6.2116305e-05 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 7.7645382e-06 2.9249735e-05 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 3.4203788e-06 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 1.1864897e-04\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      "Selected action: 21\n",
      "[[120, 125], [190, 195], [235, 240], [100, 105]]\n",
      "0.6768061552590503\n",
      "Current sequence: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0.\n",
      " 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0.]\n",
      "Valid moves: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 22, 23, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 39, 40, 41, 42, 43, 44, 45, 46, 48, 49]\n",
      "MCTS probabilities: [0.0000000e+00 7.1360823e-08 3.3448359e-06 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 7.3636611e-06 0.0000000e+00 2.6758687e-05 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 5.0018793e-06\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 6.3827051e-06 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 1.1144402e-05 0.0000000e+00 9.9977750e-01 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 1.6237865e-04\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 7.1360823e-08]\n",
      "Selected action: 32\n",
      "[[120, 125], [190, 195], [235, 240], [100, 105], [105, 110]]\n",
      "0.4823155341011739\n",
      "Current sequence: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0.\n",
      " 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0.]\n",
      "Valid moves: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 22, 23, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 39, 40, 41, 42, 43, 44, 45, 46, 48, 49]\n",
      "MCTS probabilities: [0.0000000e+00 2.9594918e-05 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 3.0280495e-05 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 5.0511703e-06 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 9.9992692e-01 7.4869872e-06 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 6.3139629e-07 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      "Selected action: 30\n",
      "[[120, 125], [190, 195], [235, 240], [100, 105], [105, 110], [160, 165]]\n",
      "0.7768878421399983\n",
      "Current sequence: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0.\n",
      " 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0.]\n",
      "Valid moves: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 22, 23, 25, 26, 27, 28, 29, 31, 33, 34, 35, 36, 37, 39, 40, 41, 42, 43, 44, 45, 46, 48, 49]\n",
      "MCTS probabilities: [0.0000000e+00 0.0000000e+00 2.3548285e-04 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 7.2170736e-04\n",
      " 0.0000000e+00 4.5738547e-04 0.0000000e+00 0.0000000e+00 3.4854513e-06\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 9.8977810e-01 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 8.8038286e-03 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      "Selected action: 18\n",
      "[[120, 125], [190, 195], [235, 240], [100, 105], [105, 110], [160, 165], [150, 155]]\n",
      "0.9238427978859004\n",
      "Current sequence: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1. 0. 0.\n",
      " 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0.]\n",
      "Valid moves: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 19, 22, 23, 25, 26, 27, 28, 29, 31, 33, 34, 35, 36, 37, 39, 40, 41, 42, 43, 44, 45, 46, 48, 49]\n",
      "MCTS probabilities: [0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 2.2025539e-07 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 9.9887866e-01\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 1.3404315e-06 3.5447895e-04\n",
      " 0.0000000e+00 8.9024681e-05 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 7.6730785e-06 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 6.6868350e-04 0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      "Selected action: 19\n",
      "[[120, 125], [190, 195], [235, 240], [100, 105], [105, 110], [160, 165], [150, 155], [90, 95]]\n",
      "0.9455070852339267\n",
      "Current sequence: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 0. 0.\n",
      " 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0.]\n",
      "Valid moves: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 22, 23, 25, 26, 27, 28, 29, 31, 33, 34, 35, 36, 37, 39, 40, 41, 42, 43, 44, 45, 46, 48, 49]\n",
      "MCTS probabilities: [0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 1.9126995e-07 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 9.9726546e-01 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 2.5392403e-03 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 1.9510805e-04\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      "Selected action: 17\n",
      "[[120, 125], [190, 195], [235, 240], [100, 105], [105, 110], [160, 165], [150, 155], [90, 95], [95, 100]]\n",
      "0.9685880626395938\n",
      "Current sequence: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 0. 0.\n",
      " 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0.]\n",
      "Valid moves: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 22, 23, 25, 26, 27, 28, 29, 31, 33, 34, 35, 36, 37, 39, 40, 41, 42, 43, 44, 45, 46, 48, 49]\n",
      "MCTS probabilities: [0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 3.5996037e-03 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 9.9441421e-01 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 1.9238786e-03\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 6.2370789e-05]\n",
      "Selected action: 33\n",
      "[[120, 125], [190, 195], [235, 240], [100, 105], [105, 110], [160, 165], [150, 155], [90, 95], [95, 100], [85, 90]]\n",
      "0.9859004019468312\n",
      "Current sequence: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 0. 0.\n",
      " 1. 0. 0. 0. 0. 0. 1. 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0.]\n",
      "Valid moves: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 22, 23, 25, 26, 27, 28, 29, 31, 34, 35, 36, 37, 39, 40, 41, 42, 43, 44, 45, 46, 48, 49]\n",
      "MCTS probabilities: [7.5425267e-01 0.0000000e+00 9.0307971e-05 2.3989590e-01 0.0000000e+00\n",
      " 0.0000000e+00 1.2771206e-06 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 1.3088748e-04 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 7.4796111e-07\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 5.6282813e-03]\n",
      "Selected action: 0\n",
      "[[120, 125], [190, 195], [235, 240], [100, 105], [105, 110], [160, 165], [150, 155], [90, 95], [95, 100], [85, 90], [165, 170]]\n",
      "0.979599406364697\n",
      "Current sequence: [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 0. 0.\n",
      " 1. 0. 0. 0. 0. 0. 1. 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0.]\n",
      "Valid moves: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 22, 23, 25, 26, 27, 28, 29, 31, 34, 35, 36, 37, 39, 40, 41, 42, 43, 44, 45, 46, 48, 49]\n",
      "MCTS probabilities: [0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 4.2817960e-06 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 1.1522545e-02 0.0000000e+00\n",
      " 0.0000000e+00 7.8979504e-01 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 2.0953021e-05 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 1.9865720e-01 0.0000000e+00]\n",
      "Selected action: 16\n",
      "[[120, 125], [190, 195], [235, 240], [100, 105], [105, 110], [160, 165], [150, 155], [90, 95], [95, 100], [85, 90], [165, 170], [0, 5]]\n",
      "0.9892452556349477\n",
      "Current sequence: [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 0. 0.\n",
      " 1. 0. 0. 0. 0. 0. 1. 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0.]\n",
      "Valid moves: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 22, 23, 25, 26, 27, 28, 29, 31, 34, 35, 36, 37, 39, 40, 41, 42, 43, 44, 45, 46, 48, 49]\n",
      "MCTS probabilities: [0.00000000e+00 2.11147111e-04 0.00000000e+00 0.00000000e+00\n",
      " 1.07758954e-01 0.00000000e+00 0.00000000e+00 1.20917195e-02\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 1.12045452e-03\n",
      " 0.00000000e+00 0.00000000e+00 2.21190458e-05 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00841571e-03 0.00000000e+00\n",
      " 8.77787232e-01 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00]\n",
      "Selected action: 28\n",
      "[[120, 125], [190, 195], [235, 240], [100, 105], [105, 110], [160, 165], [150, 155], [90, 95], [95, 100], [85, 90], [165, 170], [0, 5], [80, 85]]\n",
      "0.9954024642287822\n",
      "Current sequence: [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 0. 0.\n",
      " 1. 0. 0. 0. 1. 0. 1. 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0.]\n",
      "Valid moves: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 22, 23, 25, 26, 27, 29, 31, 34, 35, 36, 37, 39, 40, 41, 42, 43, 44, 45, 46, 48, 49]\n",
      "MCTS probabilities: [0.0000000e+00 6.6800360e-03 0.0000000e+00 1.3953421e-01 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 7.2687813e-05 0.0000000e+00 0.0000000e+00 8.5371304e-01 0.0000000e+00]\n",
      "Selected action: 48\n",
      "[[120, 125], [190, 195], [235, 240], [100, 105], [105, 110], [160, 165], [150, 155], [90, 95], [95, 100], [85, 90], [165, 170], [0, 5], [80, 85], [140, 145]]\n",
      "0.9946358753523555\n",
      "Game ended.\n"
     ]
    }
   ],
   "source": [
    "sequence = data_module.x_test[2].numpy()\n",
    "seqgame = SeqGame(sequence, standard_cnn)\n",
    "\n",
    "\n",
    "mcts_config = {\n",
    "    \"puct_coefficient\": 2.0,\n",
    "    \"num_simulations\": 10000,\n",
    "    \"temperature\": 1.5,\n",
    "    \"dirichlet_epsilon\": 0.25,\n",
    "    \"dirichlet_noise\": 0.03,\n",
    "    \"argmax_tree_policy\": False,\n",
    "    \"add_dirichlet_noise\": True,\n",
    "}\n",
    "\n",
    "model = CNN_v0(seqgame.action_size)\n",
    "model.load_state_dict(torch.load(\"best_model.pt\"))\n",
    "model.eval()\n",
    "\n",
    "mcts = MCTS(model, mcts_config)\n",
    "\n",
    "# Get the initial sequence and create the root node\n",
    "initial_sequence = seqgame.get_seq()\n",
    "    \n",
    "root_node = Node(\n",
    "    state=initial_sequence,\n",
    "    reward=0,\n",
    "    done=False,\n",
    "    action=None,\n",
    "    parent=RootParentNode(env=seqgame),\n",
    "    mcts=mcts, \n",
    "    level=0, \n",
    "    tile_ranges_done=[]\n",
    ")\n",
    "\n",
    "while not root_node.done:  # Loop until the root node indicates the game is done\n",
    "    print(\"Current sequence:\", convert_elements(root_node.state[-1,:]))\n",
    "    valid_moves = root_node.valid_actions\n",
    "    print(\"Valid moves:\", [i for i in range(seqgame.action_size) if valid_moves[i] == 1])\n",
    "\n",
    "    # Perform simulations and select an action using MCTS\n",
    "    mcts_probs, action, next_node = mcts.compute_action(root_node)\n",
    "    print(\"MCTS probabilities:\", mcts_probs)\n",
    "    print(\"Selected action:\", action)\n",
    "    \n",
    "\n",
    "    if valid_moves[action] == 0:\n",
    "        print(\"Invalid action, skipping.\")\n",
    "        continue\n",
    "    \n",
    "    print(root_node.tile_ranges_done)\n",
    "    print(root_node.reward)\n",
    "\n",
    "    root_node = next_node\n",
    "\n",
    "print(\"Game ended.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(x, tile_ranges_new, tile_ranges_ori, trials):\n",
    "    test_batch = []\n",
    "    for i in range(trials):\n",
    "        test_batch.append(x)\n",
    "        x_mut = shuffle.dinuc_shuffle(x.copy())\n",
    "        test_batch.append(x_mut)\n",
    "\n",
    "        for tile_range in tile_ranges_new:\n",
    "            ori = x.copy()\n",
    "            mut = x_mut.copy()\n",
    "            \n",
    "            ori, mut = get_swap_greedy(ori, mut, tile_ranges_ori)\n",
    "            \n",
    "            ori[:, tile_range[0]:tile_range[1]] = x_mut[:, tile_range[0]:tile_range[1]]\n",
    "            mut[:, tile_range[0]:tile_range[1]] = x[:, tile_range[0]:tile_range[1]]\n",
    "            \n",
    "            test_batch.append(ori)\n",
    "            test_batch.append(mut)\n",
    "\n",
    "    #print(np.array(test_batch).shape)\n",
    "    return np.array(test_batch)\n",
    "\n",
    "def find_max(pred, trials):\n",
    "    b_size = int(pred.shape[0]/trials)\n",
    "    loop_range = generate_tile_ranges(pred.shape[0], b_size, b_size)\n",
    "    total_score = []\n",
    "    total_score_sep = []\n",
    "    for rang in loop_range:\n",
    "        score = []\n",
    "        score_sep = []\n",
    "        p_pred = pred[rang[0]:rang[1]]\n",
    "        for i in range(0, p_pred.shape[0]-2, 2):\n",
    "            score1 = p_pred[0] - p_pred[i]\n",
    "            score2 = p_pred[i+1] - p_pred[1]\n",
    "            score.append((np.sum((score1, score2)[0])).tolist()) #np.sum(score1+score2, keepdims=True)\n",
    "            score_sep.append((score1+score2).tolist())\n",
    "\n",
    "        #print(score)\n",
    "\n",
    "        total_score.append(score)\n",
    "        total_score_sep.append(score_sep)\n",
    "\n",
    "    final = np.sum(np.array(total_score), axis=0)/trials\n",
    "\n",
    "    max_ind = np.argmax(final)\n",
    "    block_ind = np.argmax(np.array(total_score)[:, max_ind])\n",
    "    #print(np.array(total_score)[:, max_ind])\n",
    "\n",
    "    total_score = final\n",
    "    total_score_sep = np.sum(np.array(total_score_sep), axis=0)/trials\n",
    "\n",
    "\n",
    "    #print(np.max(score))\n",
    "    return total_score_sep, np.max(total_score), np.argmax(total_score), block_ind\n",
    "\n",
    "\n",
    "def get_swap_greedy(x, x_mut, tile_ranges):\n",
    "    ori = x.copy()\n",
    "    mut = x_mut.copy()\n",
    "    for tile_range in tile_ranges:\n",
    "        ori[:, tile_range[0]:tile_range[1]] = x_mut[:, tile_range[0]:tile_range[1]]\n",
    "        mut[:, tile_range[0]:tile_range[1]] = x[:, tile_range[0]:tile_range[1]]\n",
    "\n",
    "    return ori, mut\n",
    "\n",
    "def get_score(pred):\n",
    "    score1 = pred[0] - pred[2]\n",
    "    score2 = pred[3] - pred[1]\n",
    "    return (score1+score2)[0], score1+score2\n",
    "\n",
    "def generate_tile_ranges(sequence_length, window_size, stride):\n",
    "    ranges = []\n",
    "    start = np.arange(0, sequence_length - window_size + stride, stride)\n",
    "\n",
    "    for s in start:\n",
    "        e = min(s + window_size, sequence_length)\n",
    "        ranges.append([s, e])\n",
    "\n",
    "    if start[-1] + window_size - stride < sequence_length:  # Adjust the last range\n",
    "        ranges[-1][1] = sequence_length\n",
    "\n",
    "    return ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def greedy_search_ori(seq, threshold=0, trials=1):\n",
    "    a = seq\n",
    "    b = (shuffle_test.dinuc_shuffle(a.copy().transpose())).transpose()\n",
    "    max_score = 0\n",
    "    x = a\n",
    "    x_mut = b\n",
    "    tile_ranges = generate_tile_ranges(x.shape[1], 5, 5)\n",
    "    trainer = pl.Trainer(accelerator='gpu', devices='1', logger=None, enable_progress_bar=False)\n",
    "    comb_best = []\n",
    "    tile_ranges_ori = []\n",
    "    indices_list = list(range(0, 50))\n",
    "    for i in range(40):\n",
    "        batch = get_batch(x, tile_ranges, tile_ranges_ori, trials=trials)\n",
    "        #print(batch.shape)\n",
    "        dataloader = torch.utils.data.DataLoader(batch, batch_size=100, shuffle=False)\n",
    "        pred = np.concatenate(trainer.predict(standard_cnn, dataloaders=dataloader))\n",
    "        #print(pred.shape)\n",
    "        total_score, score, best, block_ind = find_max(pred, trials=trials)\n",
    "        #print(f\"Score: {score}\")\n",
    "        #print(f\"Score: {score} \\t Best Swap: {best}\")\n",
    "        if score > max_score:\n",
    "            max_score = score\n",
    "            comb_best.append(indices_list.pop(best-1))\n",
    "            tile_ranges_ori.append(tile_ranges.pop(best-1))\n",
    "            #print(block_ind*(int(pred.shape[0]/trials)))\n",
    "            # x = batch[block_ind*(int(pred.shape[0]/trials))+best*2]\n",
    "            # x_mut = batch[block_ind*(int(pred.shape[0]/trials))+best*2+1]\n",
    "        else:\n",
    "            break\n",
    "        \n",
    "\n",
    "    # comb_best.sort()\n",
    "\n",
    "    tile_ranges2 = generate_tile_ranges(x.shape[1],5,5)\n",
    "    act = []\n",
    "    for i in comb_best:\n",
    "        act.append(tile_ranges2[i])\n",
    "\n",
    "    ori, mut = get_swap_greedy(a, b, act)\n",
    "\n",
    "    batch = np.array([a, b, ori, mut])\n",
    "    dataloader = torch.utils.data.DataLoader(batch, batch_size=100, shuffle=False)\n",
    "    pred2 = np.concatenate(trainer.predict(standard_cnn, dataloaders=dataloader))\n",
    "\n",
    "    final_score, score_list = get_score(pred2)\n",
    "\n",
    "    #print(score)\n",
    "    #print(comb_best, final_score)\n",
    "    return b, comb_best, final_score, score_list, total_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_common_elements(input_list):\n",
    "    if not input_list:\n",
    "        return []  # Return an empty list if the input is empty\n",
    "\n",
    "    # Use set intersection to find common elements in all lists\n",
    "    common_elements = set(input_list[0])\n",
    "    for sublist in input_list[1:]:\n",
    "        common_elements.intersection_update(sublist)\n",
    "\n",
    "    return list(common_elements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequence 0\n",
      "[19, 17, 36, 30, 16, 24, 20, 41, 22, 28] \t 4.031272888183594\n",
      "[19, 17, 36, 30, 16, 24, 20, 22, 41, 28, 34, 12, 23, 47] \t 3.504948377609253\n",
      "[19, 17, 36, 30, 24, 16, 20, 28, 22, 41, 34, 12, 32, 47, 21, 33, 23] \t 2.9093663692474365\n",
      "[19, 17, 36, 30, 20, 24, 16, 28, 41, 22, 33, 12, 47] \t 3.801163673400879\n",
      "[19, 16, 36, 30, 17, 24, 20, 22, 41, 28, 33, 12, 32, 47, 23, 25, 34, 37, 48, 21] \t 5.245688438415527\n",
      "[19, 16, 36, 17, 24, 22, 20, 41, 34, 12, 28, 30, 23, 47, 48] \t 4.255280494689941\n",
      "[19, 16, 36, 30, 17, 24, 28, 41, 22, 20, 34, 12, 32, 23] \t 2.871603488922119\n",
      "[19, 17, 36, 30, 16, 24, 20, 41, 22, 28, 33, 12, 23, 32] \t 5.599455833435059\n",
      "[19, 17, 36, 24, 20, 16, 22, 41, 34, 12, 28, 23, 30, 47] \t 2.8981127738952637\n",
      "[19, 17, 36, 30, 20, 24, 16, 22, 41, 28, 34, 12] \t 3.2044432163238525\n",
      "The common indices among the 10 are: [36, 41, 16, 17, 19, 20, 22, 24, 28, 30]\n"
     ]
    }
   ],
   "source": [
    "for j in range(1):\n",
    "    print(f\"Sequence {j}\")\n",
    "    com = []\n",
    "    for i in range(10):\n",
    "        _, out1, out2, _, total_score = greedy_search_ori(data_module.x_test[2].numpy(), threshold=0.05, trials=200)\n",
    "        com.append(out1)\n",
    "        print(f\"{out1} \\t {out2}\")\n",
    "    print(f\"The common indices among the 10 are: {find_common_elements(com)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[95, 100], [85, 90], [80, 85], [180, 185], [150, 155], [120, 125], [100, 105], [205, 210], [140, 145], [110, 115]]\n"
     ]
    }
   ],
   "source": [
    "final_list = [19, 17, 16, 36, 30, 24, 20, 41, 28, 22]  # [40, 27, 36, 30, 24, 46, 29, 22, 17, 39, 38]\n",
    "x = data_module.x_test[1].numpy()\n",
    "\n",
    "tile_ranges2 = generate_tile_ranges(x.shape[1],5,5)\n",
    "act = []\n",
    "for i in final_list:\n",
    "    act.append(tile_ranges2[i])\n",
    "\n",
    "print(act)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "act = [[120, 125], [190, 195], [235, 240], [100, 105], [105, 110], [160, 165], [150, 155], [90, 95], [95, 100], [85, 90], [165, 170], [0, 5], [80, 85], [140, 145]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = data_module.x_test[1].numpy()\n",
    "b = (shuffle_test.dinuc_shuffle(a.copy().transpose())).transpose()\n",
    "trainer = pl.Trainer(accelerator='gpu', devices='1', logger=None, enable_progress_bar=False)\n",
    "\n",
    "scores = []\n",
    "for i in range(1, len(act)):\n",
    "    ori, mut = get_swap_greedy(a, b, act[0:i])\n",
    "\n",
    "    batch = np.array([a, b, ori, mut])\n",
    "    dataloader = torch.utils.data.DataLoader(batch, batch_size=100, shuffle=False)\n",
    "    pred2 = np.concatenate(trainer.predict(standard_cnn, dataloaders=dataloader))\n",
    "\n",
    "    final_score, score_list = get_score(pred2)\n",
    "    scores.append(score_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.5865691900253296, 0.1773701161146164], [0.944987952709198, 0.36982446908950806], [0.9513072967529297, 0.3776057958602905], [0.9911310076713562, 0.353501558303833], [0.41034793853759766, -0.047389864921569824], [-0.08887970447540283, -0.15515121817588806], [0.9737837910652161, 0.03179164230823517], [1.3044487237930298, 0.1861291080713272], [1.326135277748108, 0.18385078012943268], [1.6564514636993408, 0.2993159592151642], [1.9606178998947144, 0.3316683769226074], [1.941221833229065, 0.26242029666900635], [1.928202748298645, 0.24019253253936768]]\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(scores)):\n",
    "    scores[i] = scores[i].tolist()\n",
    "\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores2 = scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from matplotlib import rc\n",
    "rc('animation', html='jshtml')\n",
    "\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(6, 6), sharey=True)\n",
    "x = np.arange(1, len(scores1)+1)\n",
    "x2 = np.arange(1, len(scores2)+1)\n",
    "\n",
    "# artists = []\n",
    "# Pair each element of 'test' with the corresponding element of 'test2'\n",
    "container1 = ax1.plot(x, [a[0] for a in scores1], color=\"orange\")\n",
    "container2 = ax2.plot(x, [a[1] for a in scores1], color=\"orange\")\n",
    "container1 = ax1.plot(x2, [a[0] for a in scores2], color=\"blue\")\n",
    "container2 = ax2.plot(x2, [a[1] for a in scores2], color=\"blue\")\n",
    "# artists.append(container1 + container2)  # Combine the artists for both subplots in one list\n",
    "\n",
    "ax1.set_title(\"Sufficiency\")\n",
    "ax2.set_title(\"Necessity\")\n",
    "\n",
    "\n",
    "comp = animation.ArtistAnimation(fig=fig, artists=artists, interval=400)\n",
    "plt.show()\n",
    "# comp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch_test(x, tile_ranges_ori, trials):\n",
    "    test_batch = []\n",
    "    for i in range(trials):\n",
    "        test_batch.append(x)\n",
    "        x_mut = shuffle.dinuc_shuffle(x.copy())\n",
    "        test_batch.append(x_mut)\n",
    "\n",
    "        ori = x.copy()\n",
    "        mut = x_mut.copy()\n",
    "        \n",
    "        ori, mut = get_swap_greedy(ori, mut, tile_ranges_ori)\n",
    "\n",
    "        test_batch.append(ori)\n",
    "        test_batch.append(mut)\n",
    "\n",
    "    #print(np.array(test_batch).shape)\n",
    "    return np.array(test_batch)\n",
    "\n",
    "\n",
    "def get_batch_score_test(pred, trials):\n",
    "\n",
    "    score = []\n",
    "    score_sep = []\n",
    "    for i in range(0, pred.shape[0], 2):\n",
    "        # print(f\"Viewing number {i}\")\n",
    "        score1 = pred[0] - pred[i]\n",
    "        score2 = pred[i+1] - pred[1]\n",
    "        score.append((np.sum((score1, score2)[0])).tolist()) #np.sum(score1+score2, keepdims=True)\n",
    "        score_sep.append((score1+score2).tolist())\n",
    "        \n",
    "    # print(score)\n",
    "        \n",
    "    final = np.sum(np.array(score), axis=0)/trials\n",
    "\n",
    "    #max_ind = np.argmax(final)\n",
    "    #block_ind = np.argmax(np.array(score)[:, max_ind])\n",
    "    #print(np.array(total_score)[:, max_ind])\n",
    "    total_score_sep = np.sum(np.array(score_sep), axis=0)/trials\n",
    "\n",
    "    #print(np.max(score))\n",
    "    return final, total_score_sep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
